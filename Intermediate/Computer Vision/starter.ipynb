{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - Intermediate Level\n",
    "\n",
    "Welcome to the Computer Vision intermediate tasks! This notebook contains three comprehensive tasks to test your understanding of CNNs, object detection, and image segmentation.\n",
    "\n",
    "## Tasks Overview:\n",
    "1. **Task 1: Image Classification with CNNs** - Build a CNN for image classification\n",
    "2. **Task 2: Object Detection** - Implement object detection using pre-trained models\n",
    "3. **Task 3: Image Segmentation** - Perform semantic segmentation\n",
    "\n",
    "Please refer to `tasks.md` for detailed requirements for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import necessary libraries\n",
    "# You will need: numpy, matplotlib, tensorflow/keras or pytorch, opencv-cv2, PIL, etc.\n",
    "# Example:\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Image Classification with CNNs\n",
    "\n",
    "Build a Convolutional Neural Network to classify images from CIFAR-10 or Fashion MNIST dataset.\n",
    "\n",
    "**Requirements:**\n",
    "- Load and preprocess the dataset\n",
    "- Design a CNN architecture with at least 3 convolutional layers\n",
    "- Train the model and achieve at least 70% accuracy\n",
    "- Visualize training/validation loss and accuracy curves\n",
    "- Display sample predictions with confidence scores\n",
    "\n",
    "**Hints:**\n",
    "- Use `keras.datasets.cifar10.load_data()` or `keras.datasets.fashion_mnist.load_data()`\n",
    "- Normalize pixel values to [0, 1] range\n",
    "- Use Conv2D, MaxPooling2D, Dropout, and Dense layers\n",
    "- Consider using data augmentation for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 1 - Load and preprocess the dataset\n",
    "# Load your chosen dataset (CIFAR-10 or Fashion MNIST)\n",
    "# Normalize the pixel values\n",
    "# Split into training and testing sets\n",
    "# Visualize some sample images with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 2 - Build the CNN model\n",
    "# Create a Sequential model with:\n",
    "# - At least 3 Conv2D layers\n",
    "# - MaxPooling2D layers after convolutions\n",
    "# - Dropout layers to prevent overfitting\n",
    "# - Flatten layer\n",
    "# - Dense layers for classification\n",
    "# Compile the model with appropriate optimizer, loss, and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 3 - Train the model\n",
    "# Train your model using model.fit()\n",
    "# Use appropriate epochs, batch_size, and validation_split\n",
    "# Store the training history for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4 - Visualize training curves\n",
    "# Plot training and validation loss\n",
    "# Plot training and validation accuracy\n",
    "# Use matplotlib to create side-by-side plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 5 - Evaluate and display predictions\n",
    "# Evaluate the model on test data\n",
    "# Select random test images\n",
    "# Display predictions with confidence scores\n",
    "# Show original images with predicted and actual labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Object Detection\n",
    "\n",
    "Implement an object detection system using a pre-trained model (e.g., YOLO or Faster R-CNN).\n",
    "\n",
    "**Requirements:**\n",
    "- Load a pre-trained object detection model\n",
    "- Process at least 5 different test images\n",
    "- Draw bounding boxes around detected objects with labels\n",
    "- Calculate and display confidence scores for each detection\n",
    "- Handle multiple objects in a single image\n",
    "\n",
    "**Hints:**\n",
    "- Consider using TensorFlow Hub or PyTorch models\n",
    "- COCO-pretrained models work well for common objects\n",
    "- Use OpenCV for drawing bounding boxes\n",
    "- Filter detections by confidence threshold (e.g., > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 1 - Load pre-trained object detection model\n",
    "# Choose a model (YOLO, Faster R-CNN, SSD, etc.)\n",
    "# Load the model from TensorFlow Hub, PyTorch, or other source\n",
    "# Load COCO class labels if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 2 - Load and preprocess test images\n",
    "# Load at least 5 different test images\n",
    "# Preprocess images according to model requirements\n",
    "# Resize if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 3 - Run object detection\n",
    "# Run the model on each image\n",
    "# Extract bounding boxes, class labels, and confidence scores\n",
    "# Filter detections by confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4 - Visualize results\n",
    "# Draw bounding boxes on images using OpenCV or matplotlib\n",
    "# Add labels and confidence scores to each detection\n",
    "# Display all images with detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Image Segmentation\n",
    "\n",
    "Perform semantic segmentation on images using a pre-trained model or train a simple U-Net.\n",
    "\n",
    "**Requirements:**\n",
    "- Choose an appropriate dataset (e.g., Pascal VOC, Cityscapes subset)\n",
    "- Implement or load a segmentation model\n",
    "- Visualize the segmentation masks overlaid on original images\n",
    "- Calculate IoU (Intersection over Union) scores\n",
    "- Compare results on at least 3 different images\n",
    "\n",
    "**Hints:**\n",
    "- U-Net is a good architecture for segmentation\n",
    "- Consider using pre-trained DeepLab models\n",
    "- Use different colors for different classes in visualization\n",
    "- IoU = (Area of Overlap) / (Area of Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 1 - Load dataset and model\n",
    "# Choose a segmentation dataset (Pascal VOC, Cityscapes, etc.)\n",
    "# Load or build a segmentation model (U-Net, DeepLab, etc.)\n",
    "# Load pre-trained weights if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 2 - Preprocess images\n",
    "# Load at least 3 test images\n",
    "# Preprocess according to model requirements\n",
    "# Prepare ground truth masks if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 3 - Run segmentation\n",
    "# Run the model on each image\n",
    "# Get segmentation masks (pixel-wise class predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4 - Calculate IoU scores\n",
    "# Implement IoU calculation\n",
    "# Compare predictions with ground truth masks\n",
    "# Display IoU score for each class and overall mean IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 5 - Visualize segmentation results\n",
    "# Overlay segmentation masks on original images\n",
    "# Use different colors for different classes\n",
    "# Display side-by-side: original image, ground truth, prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
