{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Intermediate Level\n",
    "\n",
    "Welcome to the Deep Learning intermediate tasks! This notebook contains three comprehensive tasks to test your understanding of neural networks, transfer learning, and regularization.\n",
    "\n",
    "## Tasks Overview:\n",
    "1. **Task 1: Neural Network from Scratch** - Build a neural network using only NumPy\n",
    "2. **Task 2: Transfer Learning** - Fine-tune pre-trained models\n",
    "3. **Task 3: Regularization Techniques** - Prevent overfitting with various techniques\n",
    "\n",
    "Please refer to `tasks.md` for detailed requirements for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import necessary libraries\n",
    "# You will need: numpy, matplotlib, tensorflow/keras, sklearn, etc.\n",
    "# Example:\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Neural Network from Scratch\n",
    "\n",
    "Build a simple feedforward neural network from scratch using only NumPy.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement forward propagation\n",
    "- Implement backpropagation with gradient descent\n",
    "- Train on a simple dataset (e.g., XOR problem or MNIST subset)\n",
    "- Plot the loss curve over epochs\n",
    "- Achieve convergence and demonstrate learning\n",
    "\n",
    "**Hints:**\n",
    "- Implement activation functions (sigmoid, ReLU, softmax)\n",
    "- Use matrix operations for efficient computation\n",
    "- Initialize weights carefully (e.g., Xavier initialization)\n",
    "- Start with a simple 2-layer network, then expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 1 - Implement activation functions\n",
    "# Implement sigmoid, ReLU, and their derivatives\n",
    "# These will be used in forward and backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 2 - Initialize network parameters\n",
    "# Create weight matrices and bias vectors\n",
    "# Use appropriate initialization (Xavier, He, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 3 - Implement forward propagation\n",
    "# Compute layer outputs from input to output\n",
    "# Store intermediate values for backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4 - Implement backpropagation\n",
    "# Compute gradients using chain rule\n",
    "# Update weights and biases using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 5 - Load dataset and train\n",
    "# Load XOR dataset or MNIST subset\n",
    "# Train your network for multiple epochs\n",
    "# Track loss at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 6 - Plot learning curve\n",
    "# Visualize loss over epochs\n",
    "# Demonstrate that the network is learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Transfer Learning\n",
    "\n",
    "Use transfer learning with a pre-trained model (e.g., ResNet, VGG, or MobileNet) for a custom classification task.\n",
    "\n",
    "**Requirements:**\n",
    "- Load a pre-trained model and freeze base layers\n",
    "- Add custom classification layers\n",
    "- Fine-tune on a new dataset (at least 3 classes)\n",
    "- Compare performance with and without transfer learning\n",
    "- Visualize feature maps from different layers\n",
    "\n",
    "**Hints:**\n",
    "- Use models from keras.applications\n",
    "- Freeze early layers, train only top layers first\n",
    "- Optionally unfreeze and fine-tune later layers\n",
    "- Use appropriate data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 1 - Load dataset\n",
    "# Choose a dataset with at least 3 classes\n",
    "# Could use a subset of ImageNet, custom dataset, etc.\n",
    "# Split into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 2 - Load pre-trained model\n",
    "# Load model from keras.applications (ResNet50, VGG16, MobileNetV2, etc.)\n",
    "# Remove top layers (include_top=False)\n",
    "# Freeze base model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 3 - Add custom classification layers\n",
    "# Add GlobalAveragePooling, Dense layers\n",
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4 - Train with transfer learning\n",
    "# Train only the top layers first\n",
    "# Monitor performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 5 - Train baseline model from scratch\n",
    "# Build and train same architecture without pre-trained weights\n",
    "# Compare performance with transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 6 - Visualize feature maps\n",
    "# Extract intermediate layer outputs\n",
    "# Visualize learned features from different layers\n",
    "# Compare low-level vs high-level features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Regularization Techniques\n",
    "\n",
    "Implement and compare different regularization techniques to prevent overfitting.\n",
    "\n",
    "**Requirements:**\n",
    "- Create a baseline model on a dataset of your choice\n",
    "- Implement dropout regularization\n",
    "- Implement L1/L2 weight regularization\n",
    "- Apply batch normalization\n",
    "- Compare validation performance across all approaches\n",
    "- Visualize overfitting reduction\n",
    "\n",
    "**Hints:**\n",
    "- Use a dataset prone to overfitting (small dataset or complex model)\n",
    "- Apply one technique at a time to see individual effects\n",
    "- Monitor train vs validation metrics\n",
    "- Try combining multiple techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 1 - Create baseline model\n",
    "# Build a model that overfits (intentionally complex for the data)\n",
    "# Train without any regularization\n",
    "# Observe the gap between training and validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 2 - Implement Dropout\n",
    "# Add Dropout layers to the model\n",
    "# Train and compare with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 3 - Implement L1/L2 Regularization\n",
    "# Add kernel_regularizer to layers\n",
    "# Try L1, L2, and L1_L2 regularizers\n",
    "# Train and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4 - Implement Batch Normalization\n",
    "# Add BatchNormalization layers after Dense/Conv layers\n",
    "# Train and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 5 - Compare all approaches\n",
    "# Create comparison plots showing:\n",
    "# - Training vs validation loss for each approach\n",
    "# - Final accuracies for each approach\n",
    "# - Discussion of which techniques work best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
